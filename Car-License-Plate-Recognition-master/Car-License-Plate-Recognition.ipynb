{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car License Plate Recognition and Detection  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A easy way to impletement the Car license plate recognition by using the TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplotlib -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import pytesseract\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the image path to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the img list\n",
    "orgimg_list = []    \n",
    "def load_images_to_array(inDirectory):    \n",
    "    for img in os.listdir(inDirectory):\n",
    "\n",
    "        if os.path.splitext(img)[-1] == '.jpg' or os.path.splitext(img)[-1] == '.jpeg' or os.path.splitext(img)[-1] == '.JPG' or os.path.splitext(img)[-1] == '.png' or os.path.splitext(img)[-1] == '.PNG':\n",
    "            orgimg_list.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow detection process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, graph):\n",
    "    with graph.as_default():\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            # Get handles to input and output tensors\n",
    "            ops = tf.compat.v1.get_default_graph().get_operations()\n",
    "            all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "            tensor_dict = {}\n",
    "            for key in ['num_detections', 'detection_boxes', 'detection_scores','detection_classes', 'detection_masks']:\n",
    "                tensor_name = key + ':0'\n",
    "                if tensor_name in all_tensor_names:\n",
    "                    tensor_dict[key] = tf.compat.v1.get_default_graph().get_tensor_by_name(tensor_name)\n",
    "            if 'detection_masks' in tensor_dict:\n",
    "                # The following processing is only for single image\n",
    "                detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "                detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "                real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "                detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
    "                detection_masks_reframed = tf.cast(tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "                # Follow the convention by adding back the batch dimension\n",
    "                tensor_dict['detection_masks'] = tf.expand_dims(detection_masks_reframed, 0)\n",
    "            image_tensor = tf.compat.v1.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "            # Run inference\n",
    "            output_dict = sess.run(tensor_dict,feed_dict={image_tensor: image})\n",
    "            \n",
    "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "            output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "            output_dict['detection_classes'] = output_dict['detection_classes'][0].astype(np.int64)\n",
    "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "            if 'detection_masks' in output_dict:\n",
    "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************Total  1  images in here*************************\n"
     ]
    }
   ],
   "source": [
    "input_directory = 'test_images/'\n",
    "load_images_to_array(input_directory)\n",
    "input_directory = input_directory #get the images path with folder\n",
    "print('*************************Total ',len(orgimg_list),' images in here*************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = './car_plate_model_110K'\n",
    "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = './labelmap/labelmap.pbtxt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.compat.v2.io.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load image to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_list =  ['test_images/1230.jpg']\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_TEST_IMAGES_DIR = input_directory\n",
    "TEST_IMAGE_PATHS = []\n",
    "for orgimg in orgimg_list:\n",
    "    TEST_IMAGE_PATHS.append(os.path.join(PATH_TO_TEST_IMAGES_DIR, orgimg))\n",
    "print('image_list = ',TEST_IMAGE_PATHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the font for draw on the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = ImageFont.truetype('./font/Uknumberplate-A4Vx.ttf', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************detection start******************\n",
      "processing image:  1 /  1 ..... \n",
      "image path: test_images/1230.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-c32f51451fce>:11: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANDYC\n",
      "plate number =  ANDYC\n",
      "\f",
      "\n",
      "{'Car_Plate': [319.3380832672119, 217.24647521972656, 376.4531993865967, 454.2792510986328], 'plate_num': 'ANDYC\\n\\x0c'}\n",
      "image 1 / 1 finished.....\n",
      "['ANDYC']\n",
      "ANDYC\n",
      "******************Detection complete.******************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-c32f51451fce>:102: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "<ipython-input-12-c32f51451fce>:124: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "image_count = 1\n",
    "print('******************detection start******************')\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "#image list for return\n",
    "return_dic = {}\n",
    "for image_path in TEST_IMAGE_PATHS:\n",
    "    print('processing image: ',image_count,'/ ',len(TEST_IMAGE_PATHS),'.....','\\nimage path:',image_path)\n",
    "    image = Image.open(image_path)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    if image.format == \"PNG\":\n",
    "        #sRGB convert to RGB\n",
    "        image = image.convert('RGB')\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(image_np_expanded, detection_graph)\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        output_dict['detection_boxes'],\n",
    "        output_dict['detection_classes'],\n",
    "        output_dict['detection_scores'],\n",
    "        category_index,\n",
    "        instance_masks=output_dict.get('detection_masks'),\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=3)#To change the line width of boxes: thickness=4 (change to number what you want) deafult is 4 \n",
    "\n",
    "    plt.axis('off')\n",
    "    #get the box coordinates\n",
    "    boxes = output_dict['detection_boxes']\n",
    "    # get all boxes from an array\n",
    "    max_boxes_to_draw = boxes.shape[0]\n",
    "    # get scores to get a threshold\n",
    "    scores = output_dict['detection_scores']\n",
    "    #Accuracy rate default 0.5\n",
    "    min_score_thresh=.5\n",
    "    #image array to store the box frame eg:\"image_name1\":[{\"Land\": [0.36901385, 0.2333157, 0.5195253, 0.3745013]}...]\n",
    "    image_list = [] \n",
    "    #plate list since one image may have more than one plate\n",
    "    plate_num_list = []\n",
    "    \n",
    "    #record the plate position on the image \n",
    "    position_x_min_list = []\n",
    "    position_y_min_list = []\n",
    "    \n",
    "    plate_nums = []\n",
    "    \n",
    "    #iterate over all objects found\n",
    "    #loop all the objects \n",
    "    for i in range(min(max_boxes_to_draw, boxes.shape[0])):\n",
    "        if scores is None or scores[i] > min_score_thresh:\n",
    "            # boxes[i] is the box which will be drawn\n",
    "            class_name = category_index[output_dict['detection_classes'][i]]['name']                \n",
    "            \n",
    "            #output_dict['detection_boxes']: ymin, xmin, ymax, xmax\n",
    "            # ymin = yStart, xmin = xStart, ymax = yEnd , xmax = xEnd \n",
    "            ymin = boxes[i][0]\n",
    "            xmin = boxes[i][1]\n",
    "            ymax = boxes[i][2]\n",
    "            xmax = boxes[i][3]\n",
    "            #detected box area to image\n",
    "            (d_ymin,d_xmin,d_ymax,d_xmax) = (ymin*image.height,xmin*image.width,ymax*image.height,xmax*image.width)\n",
    "            cropped_image = tf.image.crop_to_bounding_box(image_np,int(d_ymin),int(d_xmin),int(d_ymax - d_ymin),int(d_xmax - d_xmin))\n",
    "            with tf.compat.v1.Session() as sess:\n",
    "                detect_cropped_image = sess.run(cropped_image)\n",
    "                \n",
    "                #image rgb to gary\n",
    "                gray = cv2.cvtColor(detect_cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "                gray = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "                gray = cv2.medianBlur(gray, 3)\n",
    "                \n",
    "                #image to text white list for text\n",
    "                custom_config = r'-c tessedit_char_whitelist=ABCDEFGHJKLMNPQRSTUVWXYZ1234567890 --psm 6'\n",
    "                plate_num = pytesseract.image_to_string(gray,config=custom_config)\n",
    "                \n",
    "                \n",
    "                \n",
    "                x = re.sub(r'\\n\\x0c', '', plate_num)\n",
    "                print(x)\n",
    "                plate_nums.append(x)\n",
    "                \n",
    "                \n",
    "                \n",
    "                #one image may have more than one car (plate)\n",
    "                plate_num_list.append(plate_num)\n",
    "                \n",
    "                #record the x \n",
    "                position_x_min_list.append(xmin)\n",
    "                position_y_min_list.append(ymin)\n",
    "                print('plate number = ',plate_num)\n",
    "                \n",
    "                #plate_path = out_dir_plate + '/' + orgimg_list[image_count-1]\n",
    "                #cv2.imwrite(plate_path,gray)\n",
    "                plt.imshow(gray)\n",
    "                \n",
    "                plt.show()\n",
    "            \n",
    "            #return json format\n",
    "            img_dic = {class_name: [d_ymin,d_xmin,d_ymax,d_xmax],'plate_num':plate_num}\n",
    "            image_list.append(img_dic)\n",
    "            print(img_dic)\n",
    "            \n",
    "        return_dic[orgimg_list[image_count-1]] = image_list #add array to Dictionary\n",
    "\n",
    "    #change format to image \n",
    "    im = Image.fromarray(image_np)\n",
    "    \n",
    "    #draw plate num to image\n",
    "    for img_dir in image_list:\n",
    "        car_plate_position = img_dir['Car_Plate']\n",
    "        car_plate_num = img_dir['plate_num']\n",
    "        draw = ImageDraw.Draw(im)\n",
    "        margin_y = 100\n",
    "        draw.text((car_plate_position[1], car_plate_position[0]), car_plate_num, font=font, fill='red') \n",
    "        \n",
    "    #show the img\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    \n",
    "    im.save(r'output_images/%s' % orgimg_list[image_count-1])\n",
    "    print('image',image_count,'/',len(orgimg_list),'finished.....')\n",
    "    image_count+=1\n",
    "    \n",
    "\n",
    "print(plate_nums)     \n",
    "print(plate_nums[0])  \n",
    "print('******************Detection complete.******************\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Car plate number (Database) : SR7122\n",
      "Car plate number (Camera) : ANDYC\n",
      "\n",
      "Not found Booking\n"
     ]
    }
   ],
   "source": [
    "import pyrebase\n",
    "\n",
    "config = {\n",
    "  \"apiKey\": \"AIzaSyA6Jentu7A2ClKVByHvlJ6C9lVYsyW9c64\",\n",
    "  \"authDomain\": \"fyp2021-cbba2.firebaseapp.com\",\n",
    "  \"databaseURL\": \"https://fyp2021-cbba2-default-rtdb.firebaseio.com\",\n",
    "  \"projectId\": \"fyp2021-cbba2\",\n",
    "  \"storageBucket\": \"fyp2021-cbba2.appspot.com\",\n",
    "  \"messagingSenderId\": \"648481774278\",\n",
    "  \"appId\": \"1:648481774278:web:2f60cac7b35771c674d5c7\",\n",
    " \"measurementId\": \"G-PS2EGZD81X\"\n",
    "}\n",
    "\n",
    "firebase = pyrebase.initialize_app(config)\n",
    "\n",
    "db = firebase.database()\n",
    "\n",
    "dbPlate_num = db.child(\"Booking\").child(\"Client01\").child(\"01\").child(\"car_plate\").get()\n",
    "\n",
    "print(\"\\n\\nCar plate number (Database) : \" + dbPlate_num.val())\n",
    "print(\"Car plate number (Camera) : \" + plate_nums[0])\n",
    "\n",
    "result = \"\"\n",
    "\n",
    "if dbPlate_num.val() == plate_nums[0]:\n",
    "    result = \"y\"\n",
    "    print(\"\\nConfirmed Booking\")\n",
    "else:\n",
    "    result = \"n\"\n",
    "    print(\"\\nNot found Booking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-3970ebe60c34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# session.get('http://192.168.0.150:8666/ball/' +  'result')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://192.168.0.115:8666/showResult/'\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# from requests.adapters import HTTPAdapter\n",
    "# from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "\n",
    "# session = requests.Session()\n",
    "# retry = Retry(connect=3, backoff_factor=0.5)\n",
    "# adapter = HTTPAdapter(max_retries=retry)\n",
    "# session.mount('http://', adapter)\n",
    "# session.mount('https://', adapter)\n",
    "\n",
    "# session.get('http://192.168.0.150:8666/ball/' +  'result')\n",
    "r = requests.get('http://192.168.0.115:8666/showResult/' +  result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
